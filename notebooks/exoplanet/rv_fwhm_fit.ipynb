{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run notebook_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_trace = True # set to True to rerun all traces in full; otherwise loads saved\n",
    "import pandas as pd\n",
    "import corner\n",
    "import astropy.units as u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load up HARPS data & fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/harps_rvs.csv\")\n",
    "for k in df.columns:\n",
    "    new_k = k.strip(\"#\").strip()\n",
    "    if new_k != k:\n",
    "        df[new_k] = df[k]\n",
    "        del df[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BTJD_ref = 2457000\n",
    "HARPS_upgrade = 2457218.5 # July 2015\n",
    "\n",
    "# Remove one bisector outlier\n",
    "df = df[df.bis < df.bis.max()]\n",
    "        \n",
    "df = df.sort_values(\"date\")\n",
    "\n",
    "pug = np.ascontiguousarray(df.bjd >= HARPS_upgrade, dtype=bool) # post-upgrade mask\n",
    "\n",
    "t_h1 = np.ascontiguousarray(df.bjd[~pug], dtype=np.float64)\n",
    "rv_h1 = np.ascontiguousarray(df.rv[~pug], dtype=np.float64)\n",
    "rverr_h1 = np.ascontiguousarray(df.e_rv[~pug], dtype=np.float64)\n",
    "#fwhm_h1 = np.ascontiguousarray((df.fwhm[~pug] - df.fwhm.mean()) / df.fwhm.std(), dtype=np.float64)\n",
    "fwhm_h1 = np.ascontiguousarray(df.fwhm[~pug], dtype=np.float64)\n",
    "fwhm_h1 -= np.median(fwhm_h1)\n",
    "rv_h1 -= np.median(rv_h1)\n",
    "\n",
    "t_h2 = np.ascontiguousarray(df.bjd[pug], dtype=np.float64)\n",
    "rv_h2 = np.ascontiguousarray(df.rv[pug], dtype=np.float64)\n",
    "rverr_h2 = np.ascontiguousarray(df.e_rv[pug], dtype=np.float64)\n",
    "#fwhm_h2 = np.ascontiguousarray((df.fwhm[pug] - df.fwhm.mean()) / df.fwhm.std(), dtype=np.float64)\n",
    "fwhm_h2 = np.ascontiguousarray(df.fwhm[pug], dtype=np.float64)\n",
    "fwhm_h2 -= np.median(fwhm_h2)\n",
    "rv_h2 -= np.median(rv_h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fixed zero eccentricity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_trend_order = 1\n",
    "\n",
    "t_dense = np.linspace(t_h1.min()-5, t_h2.max()+5, 1000)\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # Keplerian parameters\n",
    "    period = pm.Normal(\"period\", mu=17.47128, sd=0.00005)\n",
    "    t0 = pm.Normal(\"t0\", mu=2458661.0628, sd=0.0007)   \n",
    "    K = pm.Uniform(\"K\", lower=0., upper=10., testval=5.)\n",
    "    ecc = 0.\n",
    "    omega = np.pi\n",
    "    \n",
    "    # RV offsets\n",
    "    delta_rv = pm.Uniform(\"delta_rv\", lower=-10., upper=10.) # mu_h2 - trend[1]\n",
    "    if rv_trend_order == 1:\n",
    "        trend = pm.Uniform(\"trend\", lower=-10., upper=10.) # ideally this would be shape [1] but idk how to make that work so terrible hacks will follow\n",
    "        #trend = pm.Normal(\"trend\", mu=0, sd=3)\n",
    "    else:\n",
    "        trend = pm.Normal(\"trend\", mu=0, sd=10.0**(1-np.arange(rv_trend_order))[::-1], shape=rv_trend_order)\n",
    "    \n",
    "    # RV jitter\n",
    "    logs_h1 = pm.Uniform(\"logs_h1\", lower=0., upper=10.)\n",
    "    logs_h2 = pm.Uniform(\"logs_h2\", lower=0., upper=10.)\n",
    "    \n",
    "    # FWHM trend\n",
    "    delta_fwhm = pm.Normal(\"delta_fwhm\", mu=1., sd=5) # weak prior from eyeballing\n",
    "    trend_fwhm = pm.Normal(\"trend_fwhm\", mu=0, sd=10.0**(1-np.arange(2))[::-1], shape=2)\n",
    "            \n",
    "    # Orbit model\n",
    "    orbit_rvs = xo.orbits.KeplerianOrbit(\n",
    "        period=period,\n",
    "        ecc=ecc, omega=omega)\n",
    "    \n",
    "    # Save some helpful things for later\n",
    "    semimajor = orbit_rvs.a\n",
    "    pm.Deterministic('a', semimajor)\n",
    "    \n",
    "    # Set up the RV model and save it as a deterministic\n",
    "    # for plotting purposes later\n",
    "    vrad_h1 = orbit_rvs.get_radial_velocity(t_h1, K=K)\n",
    "    vrad_h2 = orbit_rvs.get_radial_velocity(t_h2, K=K)\n",
    "    vrad = orbit_rvs.get_radial_velocity(np.append(t_h1, t_h2), K=K)\n",
    "    pm.Deterministic(\"vrad\", vrad)\n",
    "    \n",
    "    # RV noise model for h1\n",
    "    A_fwhm_h1 = np.vander(fwhm_h1, 2)\n",
    "    bkg_terms_h1 = tt.dot(A_fwhm_h1, trend_fwhm)\n",
    "    if rv_trend_order == 1:\n",
    "        bkg_terms_h1 += trend\n",
    "    else:\n",
    "        A_trend_h1 = np.vander(t_h1, rv_trend_order)\n",
    "        bkg_terms_h1 += tt.dot(A_trend_h1, trend)\n",
    "    bkg_h1 = pm.Deterministic(\"bkg_h1\", bkg_terms_h1)\n",
    "        \n",
    "    # RV noise model for h2\n",
    "    A_fwhm_h2 = np.vander(fwhm_h2, 2)\n",
    "    bkg_terms_h2 = tt.dot(A_fwhm_h2, trend_fwhm) - delta_fwhm*trend_fwhm[0]\n",
    "    if rv_trend_order == 1:\n",
    "        bkg_terms_h2 += trend + delta_rv\n",
    "    else:\n",
    "        A_trend_h2 = np.vander(t_h2, rv_trend_order)\n",
    "        bkg_terms_h2 += tt.dot(A_trend_h2, trend) + delta_rv\n",
    "    bkg_h2 = pm.Deterministic(\"bkg_h2\", bkg_terms_h2)\n",
    "\n",
    "    # The likelihood for the RVs\n",
    "    rv_model_h1 = pm.Deterministic(\"rv_model_h1\", vrad_h1 + bkg_h1)  \n",
    "    rv_model_h2 = pm.Deterministic(\"rv_model_h2\", vrad_h2 + bkg_h2)        \n",
    "    err_h1 = tt.sqrt(rverr_h1**2 + tt.exp(2*logs_h1))\n",
    "    err_h2 = tt.sqrt(rverr_h2**2 + tt.exp(2*logs_h2))\n",
    "    pm.Normal(\"obs_h1\", mu=rv_model_h1, sd=err_h1, observed=rv_h1)\n",
    "    pm.Normal(\"obs_h2\", mu=rv_model_h2, sd=err_h2, observed=rv_h2)\n",
    "        \n",
    "    vrad_pred = orbit_rvs.get_radial_velocity(t_dense, K=K)\n",
    "    pm.Deterministic(\"vrad_pred\", vrad_pred)\n",
    "    A_pred = np.vander(t_dense, rv_trend_order)        \n",
    "    bkg_pred = pm.Deterministic(\"bkg_pred\", tt.dot(A_pred, trend))\n",
    "    pm.Deterministic(\"rv_model_pred\", vrad_pred + bkg_pred)\n",
    "\n",
    "    # Fit for the maximum a posteriori parameters\n",
    "    start = model.test_point\n",
    "    map_soln = start\n",
    "    map_soln = xo.optimize(start=map_soln, vars=[logs_h1, logs_h2, trend, delta_rv])\n",
    "    map_soln = xo.optimize(start=map_soln, vars=[trend_fwhm, delta_fwhm])\n",
    "    map_soln = xo.optimize(start=map_soln, vars=[period, t0])\n",
    "    map_soln = xo.optimize(start=map_soln, vars=[K])\n",
    "    map_soln = xo.optimize(start=map_soln)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(10, 5), sharex=True)\n",
    "\n",
    "ax = axes[0]\n",
    "ax.errorbar(t_h1, rv_h1, yerr=rverr_h1, fmt=\".k\")\n",
    "ax.errorbar(t_h2, rv_h2 - map_soln[\"delta_rv\"], yerr=rverr_h2, fmt=\".k\")\n",
    "ax.plot(t_dense, map_soln[\"vrad_pred\"], \"--k\", alpha=0.5)\n",
    "ax.plot(t_dense, map_soln[\"bkg_pred\"], \":k\", alpha=0.5)\n",
    "ax.plot(t_dense, map_soln[\"rv_model_pred\"], label=\"model\")\n",
    "ax.legend(fontsize=10)\n",
    "ax.set_ylabel(\"radial velocity [m/s]\")\n",
    "\n",
    "ax = axes[1]\n",
    "err_h1 = np.sqrt(rverr_h1**2+np.exp(2*map_soln[\"logs_h1\"]))\n",
    "err_h2 = np.sqrt(rverr_h2**2+np.exp(2*map_soln[\"logs_h2\"]))\n",
    "ax.errorbar(t_h1, rv_h1 - map_soln[\"rv_model_h1\"], yerr=err_h1, fmt=\".k\")\n",
    "ax.errorbar(t_h2, rv_h2 - map_soln[\"rv_model_h2\"], yerr=err_h2, fmt=\".k\")\n",
    "ax.axhline(0, color=\"k\", lw=1)\n",
    "ax.set_ylabel(\"residuals [m/s]\")\n",
    "ax.set_xlim(t_dense.min() - 50, t_dense.max() + 50)\n",
    "ax.set_xlabel(\"time [days]\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_trace:\n",
    "    with model:\n",
    "        trace = pm.sample(tune=1000, draws=1000, start=map_soln, chains=2,\n",
    "                      step=xo.get_dense_nuts_step(target_accept=0.9))\n",
    "    pm.save_trace(trace,directory='trace_fwhm_noecc_o{0}'.format(rv_trend_order), overwrite=True)   \n",
    "else:\n",
    "    with model:\n",
    "        trace = pm.load_trace('trace_fwhm_noecc_o{0}'.format(rv_trend_order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for varname in [\"period\", \"t0\", \"K\", \"delta_rv\", \"delta_fwhm\", \n",
    "                \"trend\", \"trend_fwhm\", \"logs_h1\", \"logs_h2\"]:\n",
    "    print(\"{0}: median {1} +{2} -{3}; MAP {4}\".format(varname, np.median(trace[varname], axis=0), \n",
    "                                                      np.percentile(trace[varname], [84], axis=0) - np.median(trace[varname], axis=0), \n",
    "                                                      np.median(trace[varname], axis=0) - np.percentile(trace[varname], [16], axis=0), \n",
    "                                                      map_soln[varname]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('period: {0:.7f} + {1:.7f} - {2:.7f}'.format(np.median(trace['period']), \n",
    "                                                    np.percentile(trace['period'], 84) - np.median(trace['period']), \n",
    "                                                    np.median(trace['period']) - np.percentile(trace['period'], 16)))\n",
    "print('t0: {0:.5f} + {1:.5f} - {2:.5f}'.format(np.median(trace['t0']), \n",
    "                                                    np.percentile(trace['t0'], 84) - np.median(trace['t0']), \n",
    "                                                    np.median(trace['t0']) - np.percentile(trace['t0'], 16)))\n",
    "print('K: {0:.2f} + {1:.2f} - {2:.2f}'.format(np.median(trace['K']), \n",
    "                                                    np.percentile(trace['K'], 84) - np.median(trace['K']), \n",
    "                                                    np.median(trace['K']) - np.percentile(trace['K'], 16)))\n",
    "if rv_trend_order>1:\n",
    "    print('mu_h1: {0:.2f} + {1:.2f} - {2:.2f}'.format(np.median(trace['trend'], axis=0)[-1], \n",
    "                                                    np.percentile(trace['trend'], 84, axis=0)[-1] - np.median(trace['trend'], axis=0)[-1], \n",
    "                                                    np.median(trace['trend'], axis=0)[-1] - np.percentile(trace['trend'], 16, axis=0)[-1]))\n",
    "    print('mu_h2: {0:.2f} + {1:.2f} - {2:.2f}'.format(np.median(trace['trend'], axis=0)[-1] + np.median(trace['delta_rv']), \n",
    "                                                    np.percentile(trace['delta_rv'], 84) - np.median(trace['delta_rv']), \n",
    "                                                    np.median(trace['delta_rv']) - np.percentile(trace['delta_rv'], 16)))\n",
    "else:\n",
    "    print('mu_h1: {0:.2f} + {1:.2f} - {2:.2f}'.format(np.median(trace['trend']), \n",
    "                                                    np.percentile(trace['trend'], 84) - np.median(trace['trend']), \n",
    "                                                    np.median(trace['trend']) - np.percentile(trace['trend'], 16)))\n",
    "    print('mu_h2: {0:.2f} + {1:.2f} - {2:.2f}'.format(np.median(trace['trend']) + np.median(trace['delta_rv']), \n",
    "                                                    np.percentile(trace['delta_rv'], 84) - np.median(trace['delta_rv']), \n",
    "                                                    np.median(trace['delta_rv']) - np.percentile(trace['delta_rv'], 16)))\n",
    "print('s_h1: {0:.2f} + {1:.2f} - {2:.2f}'.format(np.exp(np.median(trace['logs_h1'])), \n",
    "                                                    np.exp(np.percentile(trace['logs_h1'], 84)) - np.exp(np.median(trace['logs_h1'])), \n",
    "                                                    np.exp(np.median(trace['logs_h1'])) - np.exp(np.percentile(trace['logs_h1'], 16))))\n",
    "print('s_h2: {0:.2f} + {1:.2f} - {2:.2f}'.format(np.exp(np.median(trace['logs_h2'])), \n",
    "                                                    np.exp(np.percentile(trace['logs_h2'], 84)) - np.exp(np.median(trace['logs_h2'])), \n",
    "                                                    np.exp(np.median(trace['logs_h2'])) - np.exp(np.percentile(trace['logs_h2'], 16))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trace['K']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varnames = [\"period\", \"t0\", \"K\", \"trend_fwhm\", \"trend\"]\n",
    "samples = pm.trace_to_dataframe(trace, varnames=varnames)\n",
    "fig = corner.corner(samples);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the posterior median orbital parameters\n",
    "if True:\n",
    "    p = np.median(trace[\"period\"])\n",
    "    t0 = np.median(trace[\"t0\"])\n",
    "    bkg_h1 = np.median(trace[\"bkg_h1\"], axis=0)\n",
    "    bkg_h2 = np.median(trace[\"bkg_h2\"], axis=0)\n",
    "    rverr_h1_corrected = np.sqrt(rverr_h1**2+np.exp(2*np.median(trace[\"logs_h1\"])))\n",
    "    rverr_h2_corrected = np.sqrt(rverr_h2**2+np.exp(2*np.median(trace[\"logs_h2\"])))\n",
    "\n",
    "# or get the MAP parameters instead\n",
    "if False:\n",
    "    p = map_soln[\"period\"]\n",
    "    t0 = map_soln[\"t0\"]\n",
    "    bkg_h1 = map_soln[\"bkg_h1\"]\n",
    "    bkg_h2 = map_soln[\"bkg_h2\"]\n",
    "    rverr_h1_corrected = np.sqrt(rverr_h1**2+np.exp(2*map_soln[\"logs_h1\"]))\n",
    "    rverr_h2_corrected = np.sqrt(rverr_h2**2+np.exp(2*map_soln[\"logs_h2\"]))\n",
    "\n",
    "# Plot the folded data\n",
    "t_h1_fold = (t_h1 - t0 + 0.5*p) % p - 0.5*p\n",
    "t_h2_fold = (t_h2 - t0 + 0.5*p) % p - 0.5*p\n",
    "plt.errorbar(t_h1_fold, rv_h1 - bkg_h1, yerr=rverr_h1_corrected, fmt=\",k\", alpha=0.3)\n",
    "plt.errorbar(t_h2_fold, rv_h2 - bkg_h2, yerr=rverr_h2_corrected, fmt=\",k\", alpha=0.3)\n",
    "plt.errorbar(t_h1_fold, rv_h1 - bkg_h1, yerr=rverr_h1, fmt=\".k\", label=\"data\")\n",
    "plt.errorbar(t_h2_fold, rv_h2 - bkg_h2, yerr=rverr_h2, fmt=\".k\")\n",
    "\n",
    "\n",
    "bins = np.linspace(-0.5 * p, 0.5*p, 7)\n",
    "t_all_fold = np.concatenate([t_h1_fold, t_h2_fold])\n",
    "weights_all = np.concatenate([(rv_h1 - bkg_h1) / rverr_h1_corrected**2, \n",
    "                         (rv_h2 - bkg_h2) / rverr_h2_corrected**2])\n",
    "weights2_all = np.concatenate([1 / rverr_h1_corrected**2, 1 / rverr_h2_corrected**2])\n",
    "num, _ = np.histogram(t_all_fold, bins, weights=weights_all)\n",
    "denom, _ = np.histogram(t_all_fold, bins, weights=weights2_all)\n",
    "plt.errorbar(0.5*(bins[1:]+bins[:-1]), num / denom, yerr=1 / np.sqrt(denom),\n",
    "             fmt=\"o\", color=\"C2\", label=\"binned\")\n",
    "\n",
    "# Compute the posterior prediction for the folded RV model for this\n",
    "# planet\n",
    "t_fold = (t_dense - t0 + 0.5*p) % p - 0.5*p\n",
    "inds = np.argsort(t_fold)\n",
    "pred = np.percentile(trace[\"vrad_pred\"][:, inds], [16, 50, 84], axis=0)\n",
    "plt.plot(t_fold[inds], pred[1], color=\"C1\", label=\"model\")\n",
    "art = plt.fill_between(t_fold[inds], pred[0], pred[2], color=\"C1\", alpha=0.3)\n",
    "art.set_edgecolor(\"none\")\n",
    "\n",
    "\n",
    "plt.legend(fontsize=10)\n",
    "plt.xlim(-0.5*p, 0.5*p)\n",
    "plt.xlabel(\"Phase (days)\")\n",
    "plt.ylabel(\"Radial Velocity (m s$^{-1}$)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_dir+'rvphased_fwhm_noecc_o{0}.pdf'.format(rv_trend_order));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Tianjun:\n",
    "p = 17.47129\n",
    "t0 = 2458661.06279\n",
    "bkg_h1 = np.zeros_like(t_h1) + 0.64\n",
    "bkg_h2 = np.zeros_like(t_h2) + 1.28\n",
    "rverr_h1_corrected = np.sqrt(rverr_h1**2+5.32**2)\n",
    "rverr_h2_corrected = np.sqrt(rverr_h2**2+5.86**2)\n",
    "\n",
    "# Plot the folded data\n",
    "t_h1_fold = (t_h1 - t0 + 0.5*p) % p - 0.5*p\n",
    "t_h2_fold = (t_h2 - t0 + 0.5*p) % p - 0.5*p\n",
    "plt.errorbar(t_h1_fold, rv_h1 - bkg_h1, yerr=rverr_h1_corrected, fmt=\",k\", alpha=0.3)\n",
    "plt.errorbar(t_h2_fold, rv_h2 - bkg_h2, yerr=rverr_h2_corrected, fmt=\",k\", alpha=0.3)\n",
    "plt.errorbar(t_h1_fold, rv_h1 - bkg_h1, yerr=rverr_h1, fmt=\".k\", label=\"data\")\n",
    "plt.errorbar(t_h2_fold, rv_h2 - bkg_h2, yerr=rverr_h2, fmt=\".k\")\n",
    "\n",
    "\n",
    "bins = np.linspace(-0.5 * p, 0.5*p, 7)\n",
    "t_all_fold = np.concatenate([t_h1_fold, t_h2_fold])\n",
    "weights_all = np.concatenate([(rv_h1 - bkg_h1) / rverr_h1_corrected**2, \n",
    "                         (rv_h2 - bkg_h2) / rverr_h2_corrected**2])\n",
    "weights2_all = np.concatenate([1 / rverr_h1_corrected**2, 1 / rverr_h2_corrected**2])\n",
    "num, _ = np.histogram(t_all_fold, bins, weights=weights_all)\n",
    "denom, _ = np.histogram(t_all_fold, bins, weights=weights2_all)\n",
    "plt.errorbar(0.5*(bins[1:]+bins[:-1]), num / denom, yerr=1 / np.sqrt(denom),\n",
    "             fmt=\"o\", color=\"C2\", label=\"binned\")\n",
    "\n",
    "\n",
    "plt.legend(fontsize=10)\n",
    "plt.xlim(-0.5*p, 0.5*p)\n",
    "plt.xlabel(\"Phase (days)\")\n",
    "plt.ylabel(\"Radial Velocity (m s$^{-1}$)\")\n",
    "plt.tight_layout()\n",
    "#plt.savefig(plot_dir+'rvphased_fwhm_noecc.pdf');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### variable eccentricity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    # Keplerian parameters\n",
    "    period = pm.Normal(\"period\", mu=17.47128, sd=0.00005)\n",
    "    t0 = pm.Normal(\"t0\", mu=2458661.0628, sd=0.0007)   \n",
    "    K = pm.Uniform(\"K\", lower=0., upper=10., testval=5.)\n",
    "    ecc = xo.distributions.eccentricity.kipping13(\"ecc\", testval=0.01)\n",
    "    omega = xo.distributions.Angle(\"omega\", testval=np.pi)\n",
    "    \n",
    "    # RV offsets\n",
    "    delta_rv = pm.Uniform(\"delta_rv\", lower=-10., upper=10.) # mu_h2 - trend[1]\n",
    "    if rv_trend_order == 1:\n",
    "        trend = pm.Uniform(\"trend\", lower=-10., upper=10.) # ideally this would be shape [1] but idk how to make that work so terrible hacks will follow\n",
    "        #trend = pm.Normal(\"trend\", mu=0, sd=3)\n",
    "    else:\n",
    "        trend = pm.Normal(\"trend\", mu=0, sd=10.0**(1-np.arange(rv_trend_order))[::-1], shape=rv_trend_order)\n",
    "    \n",
    "    # RV jitter\n",
    "    logs_h1 = pm.Uniform(\"logs_h1\", lower=0., upper=10.)\n",
    "    logs_h2 = pm.Uniform(\"logs_h2\", lower=0., upper=10.)\n",
    "    \n",
    "    # FWHM trend\n",
    "    delta_fwhm = pm.Normal(\"delta_fwhm\", mu=1., sd=5) # weak prior from eyeballing\n",
    "    trend_fwhm = pm.Normal(\"trend_fwhm\", mu=0, sd=10.0**(1-np.arange(2))[::-1], shape=2)\n",
    "            \n",
    "    # Orbit model\n",
    "    orbit_rvs = xo.orbits.KeplerianOrbit(\n",
    "        period=period,\n",
    "        ecc=ecc, omega=omega)\n",
    "    \n",
    "    # Save some helpful things for later\n",
    "    semimajor = orbit_rvs.a\n",
    "    pm.Deterministic('a', semimajor)\n",
    "    \n",
    "    # Set up the RV model and save it as a deterministic\n",
    "    # for plotting purposes later\n",
    "    vrad_h1 = orbit_rvs.get_radial_velocity(t_h1, K=K)\n",
    "    vrad_h2 = orbit_rvs.get_radial_velocity(t_h2, K=K)\n",
    "    vrad = orbit_rvs.get_radial_velocity(np.append(t_h1, t_h2), K=K)\n",
    "    pm.Deterministic(\"vrad\", vrad)\n",
    "    \n",
    "    # RV noise model for h1\n",
    "    A_fwhm_h1 = np.vander(fwhm_h1, 2)\n",
    "    bkg_terms_h1 = tt.dot(A_fwhm_h1, trend_fwhm)\n",
    "    if rv_trend_order == 1:\n",
    "        bkg_terms_h1 += trend\n",
    "    else:\n",
    "        A_trend_h1 = np.vander(t_h1, rv_trend_order)\n",
    "        bkg_terms_h1 += tt.dot(A_trend_h1, trend)\n",
    "    bkg_h1 = pm.Deterministic(\"bkg_h1\", bkg_terms_h1)\n",
    "        \n",
    "    # RV noise model for h2\n",
    "    A_fwhm_h2 = np.vander(fwhm_h2, 2)\n",
    "    bkg_terms_h2 = tt.dot(A_fwhm_h2, trend_fwhm) - delta_fwhm*trend_fwhm[0]\n",
    "    if rv_trend_order == 1:\n",
    "        bkg_terms_h2 += trend + delta_rv\n",
    "    else:\n",
    "        A_trend_h2 = np.vander(t_h2, rv_trend_order)\n",
    "        bkg_terms_h2 += tt.dot(A_trend_h2, trend) + delta_rv\n",
    "    bkg_h2 = pm.Deterministic(\"bkg_h2\", bkg_terms_h2)\n",
    "\n",
    "    # The likelihood for the RVs\n",
    "    rv_model_h1 = pm.Deterministic(\"rv_model_h1\", vrad_h1 + bkg_h1)  \n",
    "    rv_model_h2 = pm.Deterministic(\"rv_model_h2\", vrad_h2 + bkg_h2)        \n",
    "    err_h1 = tt.sqrt(rverr_h1**2 + tt.exp(2*logs_h1))\n",
    "    err_h2 = tt.sqrt(rverr_h2**2 + tt.exp(2*logs_h2))\n",
    "    pm.Normal(\"obs_h1\", mu=rv_model_h1, sd=err_h1, observed=rv_h1)\n",
    "    pm.Normal(\"obs_h2\", mu=rv_model_h2, sd=err_h2, observed=rv_h2)\n",
    "        \n",
    "    vrad_pred = orbit_rvs.get_radial_velocity(t_dense, K=K)\n",
    "    pm.Deterministic(\"vrad_pred\", vrad_pred)\n",
    "    A_pred = np.vander(t_dense, rv_trend_order)        \n",
    "    bkg_pred = pm.Deterministic(\"bkg_pred\", tt.dot(A_pred, trend))\n",
    "    pm.Deterministic(\"rv_model_pred\", vrad_pred + bkg_pred)\n",
    "\n",
    "    # Fit for the maximum a posteriori parameters\n",
    "    start = model.test_point\n",
    "    map_soln = start\n",
    "    map_soln = xo.optimize(start=map_soln, vars=[logs_h1, logs_h2, trend, delta_rv])\n",
    "    map_soln = xo.optimize(start=map_soln, vars=[trend_fwhm, delta_fwhm])\n",
    "    map_soln = xo.optimize(start=map_soln, vars=[period, t0])\n",
    "    map_soln = xo.optimize(start=map_soln, vars=[K])\n",
    "    map_soln = xo.optimize(start=map_soln, vars=[ecc, omega])\n",
    "    map_soln = xo.optimize(start=map_soln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_trace:\n",
    "    with model:\n",
    "        trace = pm.sample(tune=1000, draws=1000, start=map_soln, chains=2,\n",
    "                      step=xo.get_dense_nuts_step(target_accept=0.9))\n",
    "    pm.save_trace(trace,directory='trace_fwhm_o{0}'.format(rv_trend_order), overwrite=True)   \n",
    "else:\n",
    "    with model:\n",
    "        trace = pm.load_trace('trace_fwhm_o{0}'.format(rv_trend_order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for varname in [\"period\", \"t0\", \"K\", \"delta_rv\", \"delta_fwhm\", \n",
    "                \"trend\", \"trend_fwhm\", \"logs_h1\", \"logs_h2\",\n",
    "                \"ecc\", \"omega\"]:\n",
    "    print(\"{0}: median {1} +{2} -{3}; MAP {4}\".format(varname, np.median(trace[varname], axis=0), \n",
    "                                                      np.percentile(trace[varname], [84], axis=0) - np.median(trace[varname], axis=0), \n",
    "                                                      np.median(trace[varname], axis=0) - np.percentile(trace[varname], [16], axis=0), \n",
    "                                                      map_soln[varname]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('period: {0:.7f} + {1:.7f} - {2:.7f}'.format(np.median(trace['period']), \n",
    "                                                    np.percentile(trace['period'], 84) - np.median(trace['period']), \n",
    "                                                    np.median(trace['period']) - np.percentile(trace['period'], 16)))\n",
    "print('t0: {0:.5f} + {1:.5f} - {2:.5f}'.format(np.median(trace['t0']), \n",
    "                                                    np.percentile(trace['t0'], 84) - np.median(trace['t0']), \n",
    "                                                    np.median(trace['t0']) - np.percentile(trace['t0'], 16)))\n",
    "print('K: {0:.2f} + {1:.2f} - {2:.2f}'.format(np.median(trace['K']), \n",
    "                                                    np.percentile(trace['K'], 84) - np.median(trace['K']), \n",
    "                                                    np.median(trace['K']) - np.percentile(trace['K'], 16)))\n",
    "if rv_trend_order>1:\n",
    "    print('mu_h1: {0:.2f} + {1:.2f} - {2:.2f}'.format(np.median(trace['trend'], axis=0)[-1], \n",
    "                                                    np.percentile(trace['trend'], 84, axis=0)[-1] - np.median(trace['trend'], axis=0)[-1], \n",
    "                                                    np.median(trace['trend'], axis=0)[-1] - np.percentile(trace['trend'], 16, axis=0)[-1]))\n",
    "    print('mu_h2: {0:.2f} + {1:.2f} - {2:.2f}'.format(np.median(trace['trend'], axis=0)[-1] + np.median(trace['delta_rv']), \n",
    "                                                    np.percentile(trace['delta_rv'], 84) - np.median(trace['delta_rv']), \n",
    "                                                    np.median(trace['delta_rv']) - np.percentile(trace['delta_rv'], 16)))\n",
    "else:\n",
    "    print('mu_h1: {0:.2f} + {1:.2f} - {2:.2f}'.format(np.median(trace['trend']), \n",
    "                                                    np.percentile(trace['trend'], 84) - np.median(trace['trend']), \n",
    "                                                    np.median(trace['trend']) - np.percentile(trace['trend'], 16)))\n",
    "    print('mu_h2: {0:.2f} + {1:.2f} - {2:.2f}'.format(np.median(trace['trend']) + np.median(trace['delta_rv']), \n",
    "                                                    np.percentile(trace['delta_rv'], 84) - np.median(trace['delta_rv']), \n",
    "                                                    np.median(trace['delta_rv']) - np.percentile(trace['delta_rv'], 16)))\n",
    "print('s_h1: {0:.2f} + {1:.2f} - {2:.2f}'.format(np.exp(np.median(trace['logs_h1'])), \n",
    "                                                    np.exp(np.percentile(trace['logs_h1'], 84)) - np.exp(np.median(trace['logs_h1'])), \n",
    "                                                    np.exp(np.median(trace['logs_h1'])) - np.exp(np.percentile(trace['logs_h1'], 16))))\n",
    "print('s_h2: {0:.2f} + {1:.2f} - {2:.2f}'.format(np.exp(np.median(trace['logs_h2'])), \n",
    "                                                    np.exp(np.percentile(trace['logs_h2'], 84)) - np.exp(np.median(trace['logs_h2'])), \n",
    "                                                    np.exp(np.median(trace['logs_h2'])) - np.exp(np.percentile(trace['logs_h2'], 16))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varnames = [\"period\", \"t0\", \"K\", \"ecc\", \"omega\", \"trend_fwhm\", \"trend\"]\n",
    "samples = pm.trace_to_dataframe(trace, varnames=varnames)\n",
    "fig = corner.corner(samples);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the posterior median orbital parameters\n",
    "if True:\n",
    "    p = np.median(trace[\"period\"])\n",
    "    t0 = np.median(trace[\"t0\"])\n",
    "    bkg_h1 = np.median(trace[\"bkg_h1\"], axis=0)\n",
    "    bkg_h2 = np.median(trace[\"bkg_h2\"], axis=0)\n",
    "    rverr_h1_corrected = np.sqrt(rverr_h1**2+np.exp(2*np.median(trace[\"logs_h1\"])))\n",
    "    rverr_h2_corrected = np.sqrt(rverr_h2**2+np.exp(2*np.median(trace[\"logs_h2\"])))\n",
    "\n",
    "# or get the MAP parameters instead\n",
    "if False:\n",
    "    p = map_soln[\"period\"]\n",
    "    t0 = map_soln[\"t0\"]\n",
    "    bkg_h1 = map_soln[\"bkg_h1\"]\n",
    "    bkg_h2 = map_soln[\"bkg_h2\"]\n",
    "    rverr_h1_corrected = np.sqrt(rverr_h1**2+np.exp(2*map_soln[\"logs_h1\"]))\n",
    "    rverr_h2_corrected = np.sqrt(rverr_h2**2+np.exp(2*map_soln[\"logs_h2\"]))\n",
    "\n",
    "# Plot the folded data\n",
    "t_h1_fold = (t_h1 - t0 + 0.5*p) % p - 0.5*p\n",
    "t_h2_fold = (t_h2 - t0 + 0.5*p) % p - 0.5*p\n",
    "plt.errorbar(t_h1_fold, rv_h1 - bkg_h1, yerr=rverr_h1_corrected, fmt=\",k\", alpha=0.3)\n",
    "plt.errorbar(t_h2_fold, rv_h2 - bkg_h2, yerr=rverr_h2_corrected, fmt=\",k\", alpha=0.3)\n",
    "plt.errorbar(t_h1_fold, rv_h1 - bkg_h1, yerr=rverr_h1, fmt=\".k\", label=\"data\")\n",
    "plt.errorbar(t_h2_fold, rv_h2 - bkg_h2, yerr=rverr_h2, fmt=\".k\")\n",
    "\n",
    "\n",
    "bins = np.linspace(-0.5 * p, 0.5*p, 7)\n",
    "t_all_fold = np.concatenate([t_h1_fold, t_h2_fold])\n",
    "weights_all = np.concatenate([(rv_h1 - bkg_h1) / rverr_h1_corrected**2, \n",
    "                         (rv_h2 - bkg_h2) / rverr_h2_corrected**2])\n",
    "weights2_all = np.concatenate([1 / rverr_h1_corrected**2, 1 / rverr_h2_corrected**2])\n",
    "num, _ = np.histogram(t_all_fold, bins, weights=weights_all)\n",
    "denom, _ = np.histogram(t_all_fold, bins, weights=weights2_all)\n",
    "plt.errorbar(0.5*(bins[1:]+bins[:-1]), num / denom, yerr=1 / np.sqrt(denom),\n",
    "             fmt=\"o\", color=\"C2\", label=\"binned\")\n",
    "\n",
    "# Compute the posterior prediction for the folded RV model for this\n",
    "# planet\n",
    "t_fold = (t_dense - t0 + 0.5*p) % p - 0.5*p\n",
    "inds = np.argsort(t_fold)\n",
    "pred = np.percentile(trace[\"vrad_pred\"][:, inds], [16, 50, 84], axis=0)\n",
    "plt.plot(t_fold[inds], pred[1], color=\"C1\", label=\"model\")\n",
    "art = plt.fill_between(t_fold[inds], pred[0], pred[2], color=\"C1\", alpha=0.3)\n",
    "art.set_edgecolor(\"none\")\n",
    "\n",
    "\n",
    "plt.legend(fontsize=10)\n",
    "plt.xlim(-0.5*p, 0.5*p)\n",
    "plt.xlabel(\"Phase (days)\")\n",
    "plt.ylabel(\"Radial Velocity (m s$^{-1}$)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_dir+'rvphased_fwhm_o{0}.pdf'.format(rv_trend_order));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesstwin",
   "language": "python",
   "name": "tesstwin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
